{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset for local Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class CIFAKE_Dataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=torchvision.transforms.ToTensor()):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = ['REAL', 'FAKE']\n",
    "        \n",
    "    def __len__(self):\n",
    "        total_len = 0\n",
    "        for cls in self.classes:\n",
    "            class_dir = os.path.join(self.root_dir, cls)\n",
    "            total_len += len(os.listdir(class_dir))\n",
    "        return total_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        \n",
    "        for cls in self.classes:\n",
    "            class_dir = os.path.join(self.root_dir, cls)\n",
    "            class_files = os.listdir(class_dir)\n",
    "            if idx < len(class_files):\n",
    "                img_name = os.path.join(class_dir, class_files[idx])\n",
    "                image = Image.open(img_name)\n",
    "                label = self.classes.index(cls)\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                return image, label\n",
    "            else:\n",
    "                idx -= len(class_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Load the dataset from local directory without preprocessing\n",
    "training_data = CIFAKE_Dataset(root_dir='data/train')\n",
    "testing_data = CIFAKE_Dataset(root_dir='data/test')\n",
    "# select only 30% of the dataset with torch.utils.data.Subset\n",
    "training_data = torch.utils.data.Subset(training_data, torch.randperm(len(training_data))[:int(len(training_data))])\n",
    "testing_data =  torch.utils.data.Subset(testing_data,  torch.randperm(len(testing_data)) [:int(len(testing_data) )])\n",
    "\n",
    "image_datasets = {'train': training_data, 'val': testing_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Defind the data loader\n",
    "train_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(testing_data, batch_size=64, shuffle=True)\n",
    "dataloaders = {'train': train_loader, 'val': test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beik/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/beik/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = models.resnet50(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, num_classes),\n",
    "    nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5587 Acc: 0.7558\n",
      "val Loss: 0.5184 Acc: 0.7894\n",
      "train Loss: 0.5117 Acc: 0.7935\n",
      "val Loss: 0.5001 Acc: 0.8068\n",
      "train Loss: 0.5034 Acc: 0.8012\n",
      "val Loss: 0.4922 Acc: 0.8139\n",
      "train Loss: 0.4974 Acc: 0.8072\n",
      "val Loss: 0.4865 Acc: 0.8203\n",
      "train Loss: 0.4936 Acc: 0.8112\n",
      "val Loss: 0.4887 Acc: 0.8193\n",
      "train Loss: 0.4913 Acc: 0.8127\n",
      "val Loss: 0.4825 Acc: 0.8224\n",
      "train Loss: 0.4895 Acc: 0.8143\n",
      "val Loss: 0.4857 Acc: 0.8175\n",
      "train Loss: 0.4876 Acc: 0.8160\n",
      "val Loss: 0.4764 Acc: 0.8299\n",
      "train Loss: 0.4850 Acc: 0.8193\n",
      "val Loss: 0.4760 Acc: 0.8282\n",
      "train Loss: 0.4841 Acc: 0.8196\n",
      "val Loss: 0.4765 Acc: 0.8275\n"
     ]
    }
   ],
   "source": [
    "with open('resnet50_finetuned.log', 'w') as f:\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            corrects = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / len(image_datasets[phase])\n",
    "            epoch_acc = corrects.double() / len(image_datasets[phase])\n",
    "            \n",
    "            print(  '{} Loss: {:.4f} Acc: {:.4f}'  .format(phase, epoch_loss, epoch_acc))\n",
    "            f.write('{} Loss: {:.4f} Acc: {:.4f}\\n'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'resnet50_finetuned.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IntroToAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
