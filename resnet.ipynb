{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset for local Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAKE_Dataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=torchvision.transforms.ToTensor()):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = ['REAL', 'FAKE']\n",
    "        \n",
    "    def __len__(self):\n",
    "        total_len = 0\n",
    "        for cls in self.classes:\n",
    "            class_dir = os.path.join(self.root_dir, cls)\n",
    "            total_len += len(os.listdir(class_dir))\n",
    "        return total_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        \n",
    "        for cls in self.classes:\n",
    "            class_dir = os.path.join(self.root_dir, cls)\n",
    "            class_files = os.listdir(class_dir)\n",
    "            if idx < len(class_files):\n",
    "                img_name = os.path.join(class_dir, class_files[idx])\n",
    "                image = Image.open(img_name)\n",
    "                label = self.classes.index(cls)\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                return image, label\n",
    "            else:\n",
    "                idx -= len(class_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from local directory without preprocessing\n",
    "training_data = CIFAKE_Dataset(root_dir='data/train')\n",
    "testing_data = CIFAKE_Dataset(root_dir='data/test')\n",
    "# select only 30% of the dataset with torch.utils.data.Subset\n",
    "training_data = torch.utils.data.Subset(training_data, torch.randperm(len(training_data))[:int(0.3*len(training_data))])\n",
    "testing_data =  torch.utils.data.Subset(testing_data,  torch.randperm(len(testing_data)) [:int(0.3*len(testing_data) )])\n",
    "\n",
    "image_datasets = {'train': training_data, 'val': testing_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defind the data loader\n",
    "train_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(testing_data, batch_size=64, shuffle=True)\n",
    "dataloaders = {'train': train_loader, 'val': test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "model = models.resnet50(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, num_classes),\n",
    "    nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6129 Acc: 0.7139\n",
      "val Loss: 0.5611 Acc: 0.7615\n",
      "train Loss: 0.5447 Acc: 0.7720\n",
      "val Loss: 0.5283 Acc: 0.7875\n",
      "train Loss: 0.5255 Acc: 0.7847\n",
      "val Loss: 0.5186 Acc: 0.7885\n",
      "train Loss: 0.5189 Acc: 0.7892\n",
      "val Loss: 0.5102 Acc: 0.7995\n",
      "train Loss: 0.5121 Acc: 0.7953\n",
      "val Loss: 0.5051 Acc: 0.8053\n",
      "train Loss: 0.5095 Acc: 0.7951\n",
      "val Loss: 0.5023 Acc: 0.8057\n",
      "train Loss: 0.5065 Acc: 0.7979\n",
      "val Loss: 0.5007 Acc: 0.8060\n",
      "train Loss: 0.5035 Acc: 0.8021\n",
      "val Loss: 0.4975 Acc: 0.8063\n",
      "train Loss: 0.4987 Acc: 0.8068\n",
      "val Loss: 0.4940 Acc: 0.8132\n",
      "train Loss: 0.4990 Acc: 0.8054\n",
      "val Loss: 0.4947 Acc: 0.8102\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        corrects = 0\n",
    "        \n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "        epoch_loss = running_loss / len(image_datasets[phase])\n",
    "        epoch_acc = corrects.double() / len(image_datasets[phase])\n",
    "        \n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'resnet50_finetuned.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IntroToAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
