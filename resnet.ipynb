{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import os\n",
    "from model_training import ResNet, BottleNeck, ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset for local Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAKE_Dataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = ['REAL', 'FAKE']\n",
    "        \n",
    "    def __len__(self):\n",
    "        total_len = 0\n",
    "        for cls in self.classes:\n",
    "            class_dir = os.path.join(self.root_dir, cls)\n",
    "            total_len += len(os.listdir(class_dir))\n",
    "        return total_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        for cls in self.classes:\n",
    "            class_dir = os.path.join(self.root_dir, cls)\n",
    "            if idx < len(os.listdir(class_dir)):\n",
    "                img_name = os.listdir(class_dir)[idx]\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                image = Image.open(img_path)\n",
    "                label = self.classes.index(cls)\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                return image, label\n",
    "            else:\n",
    "                idx -= len(os.listdir(class_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from local directory without preprocessing\n",
    "training_data = CIFAKE_Dataset(root_dir='data/CIFAKE Real and AI-Generated Images/train')\n",
    "testing_data = CIFAKE_Dataset(root_dir='data/CIFAKE Real and AI-Generated Images/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defind the data loader\n",
    "train_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(testing_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "net = ResNet50(10).to('cuda')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "for epoch in range(EPOCHS):\n",
    "    losses = []\n",
    "    running_loss = 0\n",
    "    for i, inp in enumerate(train_loader):\n",
    "        inputs, labels = inp\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i%100 == 0 and i > 0:\n",
    "            print(f'Loss [{epoch+1}, {i}](epoch, minibatch): ', running_loss / 100)\n",
    "            running_loss = 0.0\n",
    "\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(avg_loss)\n",
    "            \n",
    "print('Training Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IntroToAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
